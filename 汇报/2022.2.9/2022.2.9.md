## 已解决python 透视变换后部分图像丢失的问题

实例：
before:

<img src="D:\Courses\IPP\汇报\2022.2.9\g.jpg" alt="g" style="zoom:11.5%;" />

after (之前有部分裁剪丢失的结果):

<img src="D:\Courses\IPP\汇报\2022.2.9\c_3.jpg" alt="c_3" style="zoom:14%;" />

after（现在完全保留的情况）:

<img src="D:\Courses\IPP\汇报\2022.2.9\c_test_7.jpg" alt="c_test" style="zoom:13%;" />

另一个示例：

before：

<img src="D:\Courses\IPP\汇报\2022.2.9\b.jpg" alt="b" style="zoom:13%;" />

after:

<img src="D:\Courses\IPP\汇报\2022.2.9\c_test.jpg" alt="c_test" style="zoom:9%;" />



### 目前没有出现任何问题，可以实现所需要求，改进过程&方法：

1. 原因是在矫正过后一些像素坐标会转换到负轴上，导致无法显示。（同张泽宇上周汇报的内容和原因一致
2. 第一步：取消原来相机去除畸变时使用的ROI(region of interest)裁剪（但仍然保留alpha参数=1）
3. 第二步：在进行透视消除时先取原画幅尺寸的四个角点，然后乘初步得到的单应性矩阵M，并判断是否有点落入负轴。若有负轴情况出现，则分别取最小的横纵坐标并取负数作为平移矩阵T的参数，在与原来的单应性矩阵相乘（T*M）作为新的单应性矩阵，然后进行转换，得到最终结果。

参考stackoverflow论坛网址：

https://stackoverflow.com/questions/6087241/opencv-warpperspective/37275961#37275961

部分代码：

```python
    [x_min, y_min] = np.int32(pts_.min(axis=0).ravel()-0.5)
    [x_max, y_max] = np.int32(pts_.max(axis=0).ravel()+0.5)
    diff = [-x_min, -y_min]
    H_diff = np.array([[1, 0, diff[0]], [0, 1, diff[1]], [0, 0, 1]])
    H = H_diff.dot(M)
```

### 一些问题和下一步计划：

1. 速度比较慢，但还是缘于识别棋盘角点的问题，与此次优化无关
2. 下一步可以尝试测试不同方位对精度的影响，初步得到一些指导性的结论