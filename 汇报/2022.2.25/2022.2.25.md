

## 原代码(识别圆形、计算坐标部分)review:

### class CropLayer:

类，用于裁剪图片

### local_grid: （得到四个地脚螺栓的中心坐标）

1. 高斯模糊，canny处理
2. 霍夫圆识别， 得到半径在20像素-50像素之间可能的圆
2. 利用聚类方法KMeans,  将识别的所有圆的坐标分成四组，然后按纵坐标正序排列，选取最小的作为结果
2. 得到4个圆形的坐标、半径，对横纵坐标分别取mean值，减去画幅长/2和宽/2，得到四个地脚螺栓的中心坐标（原点为图片中心）

霍夫圆识别（函数、参数）：

**HoughCircles(re_noise,cv2.HOUGH_GRADIENT,1,20,param1==100,param2=30,minRadius=0,maxRadius=100)**
对此参数进行以下解释：

re_noise时对一幅彩色图片进行处理之后的单通道灰度图片

HOUGH_GRADIENT:是使用霍夫梯度法检测圆

1：这个参数是double类型的dp，用来检测圆心的累加器图像的分辨率于输入图像之比的倒数，且此参数允许创建一个比输入图像分辨率低的累加器。例如，如果dp= 1时，累加器和输入图像具有相同的分辨率。如果dp=2，累加器便有输入图像一半那么大的宽度和高度

20：minDist表示两个圆之间圆心的最小距离

param1:此参数是对应Canny边缘检测的最大阈值，最小阈值是此参数的一半 也就是说像素的值大于param1是会检测为边缘

param2:它表示在检测阶段圆心的累加器阈值。它越小的话，就可以检测到更多根本不存在的圆，而它越大的话，能通过检测的圆就更加接近完美的圆形了

minRadius:表示能够检测的最小圆的半径 这里设置为0是因为也要检测圆心 而圆心可以看作是半径为0的圆

maxRadius：表示能够检测的最大圆的半径，这里设置为100，那么表示圆半径大于100的圆不会被检测出来（这个是依据要检测的图片而考虑）




**但是我按原代码的操作流程测试了该方法，发现有很大问题：**

原图：

<img src="D:\Courses\SJTU-IPP-Program2022\汇报\2022.2.25\227310620698943970.jpg" alt="227310620698943970" style="zoom:10%;" />

<img src="D:\Courses\SJTU-IPP-Program2022\汇报\2022.2.25\屏幕截图 2022-02-23 161720.jpg" alt="屏幕截图 2022-02-23 161720" style="zoom:35%;" />

可以看到，理论上应该取到中间的四个螺栓的圆形，但实际上检测的只有一个符合要求，其余三个识别到外部的泥土、鞋子上了。

### HED：（利用神经网络进行边缘识别，理论优于canny）

1. 传入一个net变量，该变量由cv.dnn.readNetFromCaffe函数和 protoPath = "deploy.prototxt"， modelPath = "hed_pretrained_bsds.caffemodel" 加载序列化的边缘检测器模型（在最终process_image函数中）
2. 将图像转成blob，设置一些参数，传入net中，进行操作

详情可见https://blog.csdn.net/qq_40985985/article/details/116495758

### base_X：（找基座的中心（相对棋盘格中心的横坐标差））

1. 先将图片按比例裁剪，使得棋盘格尽可能占满照片
2. 用cv.findChessboardCorners找棋盘格
3. 再把识别到的棋盘格坐标还原成原坐标，并把中心棋盘格坐标设置为中心
4. 判断方向，得到棋盘格单位长度
5. 边缘识别（法一：HED，法二：canny），得到hed图像
6. 用cv.findContours 寻找hed图像中闭合的轮廓
7. 选取面积大于图片1/2的轮廓作为地基轮廓
8. 用图像矩求解该封闭轮廓的重心（即地基的中心）![屏幕截图 2022-02-23 183025](D:\Courses\SJTU-IPP-Program2022\汇报\2022.2.25\屏幕截图 2022-02-23 183025.jpg)
9. 将该重心的横坐标与棋盘格中心横坐标相减（像素），**并乘以比例（d/32）**,d为棋盘格单位边长的像素长度，并返回棋盘格方向。（乘比例并不是很懂）

### base_grid2：（获得基座中心相对于棋盘格中心的横纵坐标）

1. 对所有照片进行base_X()调用，得到距离和方向的list
2. 如果正常返回值，则进行聚类（2类）
3. 抛弃outlier
4. 找到最小值，对聚类结果进行取mean和最大值操作，取得最终的最大值
5. 返回最小值和根号（绝对值（最大值平方-最小值平方））【个人理解：把棋盘格最接近水平/垂直的照片上的x轴距离作为最终坐标的横坐标，将所有照片x轴距离中最大的作为基座中心到棋盘格中心的直接距离，然后用勾股定理求解纵坐标】
6. 调用direction函数，得到该照片的方向
6. 根据方向调整坐标正负（正代表在棋盘格中心右边、下边，负则反之）

### base_grid：（获得基座中心相对于照片中心的坐标）

1. 利用HED识别边缘
2. 再用霍夫圆识别轮廓，参数选取较大的半径以尽可能识别基座
3. 然后对识别到的圆求其圆心关于图片中心的坐标（同时加上一个因为hed造成的修正参数）
4. 之前490document上写的该函数得到的是基座圆心关于棋盘格中心的坐标，但我观察之后发现返回的只是关于照片中心的坐标。

### square_grid_NN:(方形基座，目前省略)

### square_grid_normal:(方形基座，目前省略)

### bwareaopen:(helper函数，用于square_grid_normal，略)

### direction:（确定棋盘格方位）

1. 灰度处理后，截取照片中间部分，使得棋盘格占照片尽可能大
2. 进行棋盘格角点识别，并返还成原尺寸大小的坐标
3. 二极化图片（黑白化），出于棋盘格如下的特征（部分有空心圆），可以利用这一特征判断方向
4. 分别取左上、左下、右上、右下四个角上四个棋盘格角点的平均值，取到每个角上正方形的中心坐标，并判断该处是否有像素（是否为黑/白）
5. 但据原代码注释，该角度不是拍摄角度（我review过确实如此，但是仍然不太懂具体是指什么角度）
6. 分别返还0，90，180，-90



<img src="D:\Courses\SJTU-IPP-Program2022\汇报\2022.2.25\chessboard.jpg" alt="chessboard" style="zoom:33%;" />

## obthomography:(透视变换)

针对相机畸变消除、透视变换，我已经修改原错误代码，重新写好该部分的所有函数，在文件undistort_perspective.py 中。

### processimage：（主函数，调用所有子函数处理）

1. 读取文件
2. 相机畸变，得到畸变参数（读取所有文件、选取棋盘格角点）
3. 用dnn读取net模型（用于边缘识别）
4. 读取所有图片中地基的坐标，并且调用base_grid2函数得到最终坐标
5. 选取特定数量的照片，进行处理
6. 进行畸变消除，透视变换，灰度处理
7. 调用local_grid，得到地脚螺栓的中心，并根据方向调整
8. 根据flag选取寻找地基中心的方法，最终得到地基中心（相对于棋盘格）
9. 计算结果
