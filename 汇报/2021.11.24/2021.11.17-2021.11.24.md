# 2021.11.17-2021.11.24

### local_grid

```python
def local_grid(gray):
    # detect the center of bolts relative to the centre of
    (H, W) = gray.shape[:2]
    blurred = cv.GaussianBlur(gray, (5, 5), 0)
    canny = cv.Canny(blurred, 30, 150)
    # obtain edge through Canny alogrithm
    circleshed = cv.HoughCircles(canny, cv.HOUGH_GRADIENT, 1, 20,
                                 param1=100, param2=16,
                                 minRadius=20, maxRadius=50)
    # use K-means algorithm to group the circles and extract the minimum from each groups
    km = KMeans(n_clusters=4).fit(circleshed[0, :, 0:2])
    df = pd.DataFrame({'X': circleshed[0, :, 0],
                       'Y': circleshed[0, :, 1],
                       'Radius': circleshed[0, :, 2],
                       'Label': km.labels_}
                      )
    mins = df.sort_values('Y', ascending=False).groupby('Label', as_index=False).first()
    # show the circles
    # for index, i in mins.iterrows():
    #     center = (i['X'].astype("int"), i['Y'].astype("int"))
    #     cv.circle(canny, center, 1, (255, 255, 255), 3)
    #     radius = i['Radius'].astype("int")
    #     cv.circle(canny, center, radius, (255, 255, 255), 3)
    # cv.imshow("canny", canny)
    # cv.waitKey()
    return (mins['X'].mean() - W / 2, mins['Y'].mean() - H / 2)
```

- 函数用途：检测螺栓中心相对棋盘格中心的坐标；
- 运用高斯模糊、canny边缘识别、霍夫圆检测的方法得到四个螺栓的圆形形状；
- 用pandas模块内的dataframe对霍夫圆检测得到的数组进行排序和操作，得到x方向和y方向的mean值作为中心点坐标。

### HED

```python
def HED(image, net, downW=800, downH=800):
    (H, W) = image.shape[:2]
    image = cv.resize(image, (downW, downH))
    # 根据输入图像为全面的嵌套边缘检测器（Holistically-Nested Edge Detector）构建一个输出blob
    blob = cv.dnn.blobFromImage(image, scalefactor=1.0, size=(800, 800),
                                mean=(104.00698793, 116.66876762, 122.67891434),
                                swapRB=False, crop=True)

    # # 设置blob作为网络的输入并执行算法以计算边缘图
    print("[INFO] performing holistically-nested edge detection...")
    net.setInput(blob)
    hed = net.forward()
    # 调整输出为原始图像尺寸的大小
    hed = cv.resize(hed[0, 0], (W, H))
    # 将图像像素缩回到范围[0,255]并确保类型为“UINT8”
    hed = (255 * hed).astype("uint8")
    return hed
```

- 函数用途：运用

  ```python
  blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size, mean, swapRB=True，crop=False,*ddepth* = `CV_32F` 
  ```

  函数进行边缘识别。

- 该方法先对数据进行预处理然后神经网络的进行数据的预测；

- 关于net类型，涉及opencv dnn模块；（后面单独列举）

- Net类的定义：这个类中定义了创建和操作网络的方法；

### base_X

```python
def base_X(image, net):
    print("baseX start")
    # 找棋盘格的中心
    size = image.shape
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)
    gray1 = cv.cvtColor(
        image[math.ceil(size[0] / 3):math.ceil(2 * size[0] / 3), math.ceil(size[1] / 4):math.ceil(3 * size[1] / 4)],
        cv.COLOR_BGR2GRAY)
    print("gray complete")
    ret, corners = cv.findChessboardCorners(gray1, (5, 5), None)
    # print(corners)
    for each in corners:
        each[0][1] += math.ceil(size[0] / 3)
        each[0][0] += math.ceil(size[1] / 4)
    print("find corners")
    if ret == False:
        return 0, 100
    print("judge direction")
    # 判断棋盘格与相机光轴的相对方向
    vd1 = corners[2][0] - corners[-3][0]
    vd2 = corners[10][0] - corners[14][0]
    dir = min(abs(vd1[0] / vd1[1]), abs(vd2[0] / vd2[1]))
    # 判断棋盘格的单位长度
    v = corners[12][0] - corners[13][0]
    d = math.sqrt(v[0] * v[0] + v[1] * v[1])
    # 边缘识别
    (H, W) = image.shape[:2]
    blurred = cv.GaussianBlur(gray, (5, 5), 0)
    if NN_FLAG:
        hed = HED(image, net, downW=400, downH=400)  # 如果无法识别请改用神经网络
    else:
        hed = cv.Canny(cv.resize(blurred, (800, 600)), CANNY_PARAMETER[0], CANNY_PARAMETER[1])
    center = corners[12][0]
    hed = cv.resize(hed, (W, H))
    # 找闭合轮廓
    contours, hier = cv.findContours(hed, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)
    print("start finding min")
    for cnt in contours:
        print("start cnt")
        # 筛出小轮廓，找到地基轮廓
        if cv.contourArea(cnt) > H * W * 0.2:
            print("cnt calculated")
            M = cv.moments(cnt)
            cx = int(M['m10'] / M['m00'])
            cy = int(M['m01'] / M['m00'])
            # # Show the center detection
            # cv.circle(hed, (int(center[0]), int(center[1])), 20, (255, 255, 255), 3)
            # cv.circle(hed, (cx,cy), 20, (255, 255, 255), 3)
            # cv.imshow("hed", cv.resize(hed, (800, 600)))
            # cv.waitKey()
            l = abs(cx - center[0])
            return l / d * 32, dir
    return 0, 100
```

- 函数用途：用于计算地基主柱关于棋盘格中心的坐标
- 运用opencv中findChessboardCorners寻找棋盘格角点，然后运用canny边缘识别和findcontour函数去判断主柱地基的轮廓，函数选取面积大于整个图片尺寸一半的轮廓作为地基轮廓。
- findcontour函数涉及图像矩，进一步计算x,y坐标

![image-20211121232929113](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20211121232929113.png)

## base_grid2

```python
def base_grid2(images, net):
    print("base_grid2 start")
    ids = []
    lens = []
    dirs = []
    for index, fname in enumerate(images):
        image = cv.imread(fname)
        l, d = base_X(image, net)
        ids.append(index)
        lens.append(l)
        dirs.append(d)
    print("index and fname complete")
    if (np.array(dirs) == 100).all():
        global FAILURE_FLAG
        FAILURE_FLAG = True
        print("Detection failure, please consider use Neural Network/Old Method for base detection!")
        return 0, 0
    print("start kMeans")
    km = KMeans(n_clusters=2).fit(np.array(lens).reshape(-1, 1))
    print("end kMeans\nstart df")
    df = pd.DataFrame({'index': ids,
                       'l': lens,
                       'dir': dirs,
                       'label': km.labels_
                       })
    df = df[((df['l'] - df['l'].mean()) / df['l'].std()) < 1]  # Remove outliers that are too large
    print("end df")
    # print(df.to_string())
    # 寻找棋盘格最接近垂直/水平的帧
    print("start to find min or max")
    minf = df[df.dir == df.dir.min()]
    lmin = minf['l'].values[0]
    idmin = int(minf['index'].values)
    # 用聚类方法减少寻找最大值过程中产生的偏差
    lmax = df.groupby('label', as_index=False)[["l"]].mean().max().values[1]
    ret = (lmin, math.sqrt(abs(lmax * lmax - lmin * lmin)))
    print("found min or max")
    # 判断这一帧的方向
    print("start judge")
    dir = direction(cv.imread(images[idmin]))
    print("end judge")
    if dir == 90:
        ret = (ret[1], -ret[0])
    elif dir == 180:
        ret = (-ret[0], -ret[1])
    elif dir == -90:
        ret = (-ret[1], ret[0])
    return ret
```

- 函数用途：寻找圆形地基主柱相对于棋盘格中心的坐标。
- 运用sklearn模块中k-means算法进行聚类，来减少找最大值过程中的偏差，最后返回ret类型
- 新的算法：简单的通过使棋盘格对准并不能解决y轴畸变；但是畸变对椭圆的x轴坐标⼏乎不会产⽣影响，因此可以通过记录每张图⽚中圆⼼与棋盘格中⼼在X轴上的距离，和棋盘格的⼤致⾓度，根据两点最⼤横向距离等于平⾯距离，利⽤统计学⽅法求出圆⼼与棋盘格中⼼X轴，Y轴的相对坐标。

## base_grid

```python
def base_grid(image, net, corr=90):
    # detect the center of round base
    # The result of HED is skewed from original picture, corr is a corrective item
    hed = HED(image, net)
    # HED seems to have some blur
    (H, W) = hed.shape[:2]
    circleshed = cv.HoughCircles(hed, cv.HOUGH_GRADIENT, 1, round(H / 2),
                                 param1=100, param2=50,
                                 minRadius=round(H / 4), maxRadius=round(H / 2))
    # show the circle
    # df = pd.DataFrame({'X': circleshed[0, :, 0],
    #                    'Y': circleshed[0, :, 1],
    #                    'Radius': circleshed[0, :, 2]}
    #                   )
    # for index, i in df.iterrows():
    #     center = (i['X'].astype("int"), i['Y'].astype("int"))
    #     cv.circle(hed, center, 1, (255, 255, 255), 3)
    #     radius = i['Radius'].astype("int")
    #     cv.circle(hed, center, radius, (255, 255, 255), 3)
    # cv.circle(hed, (round(W/2 + corr),round(H/2 + corr)), 1, (255, 255, 255), 3)
    # cv.imshow("hed", cv.resize(hed, (800, 800)))
    # cv.waitKey()
    return circleshed[0, 0, 0] - W / 2 - corr, circleshed[0, 0, 1] - H / 2 - corr
```

- 函数用途：找到圆形地基中⼼相对于棋盘格中⼼的坐标(旧算法)
- 简单地运用霍夫圆检测去找到圆心坐标



## square_grid_NN

```python
def square_grid_NN(image, net):
    # detect center of squared base
    # ! Notice this method is untested
    hed = HED(image, net)
    (H, W) = hed.shape[:2]
    contours, hier = cv.findContours(hed, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)
    for cnt in contours:
        if cv.contourArea(cnt) > H * W * 0.2:  # remove small areas like noise etc
            hull = cv.convexHull(cnt)  # find the convex hull of contour
            hull = cv.approxPolyDP(hull, 0.1 * cv.arcLength(hull, True), True)
            if len(hull) == 4:
                M = cv.moments(cnt)
                cx = int(M['m10'] / M['m00'])
                cy = int(M['m01'] / M['m00'])
                center = (cx - W / 2, cy - W / 2)
                return center
    return 0, 0  # default value if unable to find center
```

- 函数用途：寻找方形地基的中心坐标
- 调用HED函数（神经网络），和findcontours，方法与圆形类似



## bwareaopen

```python
def bwareaopen(img, th):
    ## Helper function for removing smaller
    cnts = cv.findContours(img, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)
    cnts = cnts[0] if len(cnts) == 2 else cnts[1]
    for c in cnts:
        area = cv.contourArea(c)
        if area < th:
            cv.drawContours(img, [c], -1, (0, 0, 0), -1)

    # Morph close
    kernel = cv.getStructuringElement(cv.MORPH_RECT, (5, 5))
    close = cv.morphologyEx(img, cv.MORPH_CLOSE, kernel, iterations=2)
    return close

```

- 函数用途：helper function for **square_grid_normal**



## square_grid_normal

```python
def square_grid_normal(image):
    # detect center of squared base
    # ! Notice this is only tried on ONE sample picture is provided
    dst = image[:, :, 0]
    thresh = cv.threshold(dst, 255 * 0.4, 255, cv.THRESH_BINARY)[1]
    h, w = image.shape[:2]
    th = round(h * w * 0.1)

    close = bwareaopen(thresh, th)
    kernel = np.ones((5, 5), np.uint8)
    close = bwareaopen(255 - cv.dilate(close, kernel, iterations=1), th)
    mask = bwareaopen(255 - cv.dilate(close, kernel, iterations=1), th)

    contours, hier = cv.findContours(mask, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)
    for cnt in contours:
        if cv.contourArea(cnt) > 2 * th:  # remove small areas like noise etc
            hull = cv.convexHull(cnt)  # find the convex hull of contour
            hull = cv.approxPolyDP(hull, 0.1 * cv.arcLength(hull, True), True)
            if len(hull) == 4:
                M = cv.moments(cnt)
                cx = int(M['m10'] / M['m00'])
                cy = int(M['m01'] / M['m00'])
                center = (cx - w / 2, cy - w / 2)
                return center
    return 0, 0  # default value if unable to find center
```

- 使⽤形态学变换找到⽅形地基的坐标 (最终未使用？)

## direction

```python
def direction(dst):
    direction = 0  # This is to ensure the robustness of default case
    gray = cv.cvtColor(dst, cv.COLOR_BGR2GRAY)
    image = dst
    size = image.shape
    gray1 = cv.cvtColor(
        image[math.ceil(size[0] / 3):math.ceil(2 * size[0] / 3), math.ceil(size[1] / 4):math.ceil(3 * size[1] / 4)],
        cv.COLOR_BGR2GRAY)
    ret, corners = cv.findChessboardCorners(gray1, (5, 5), None)
    for each in corners:
        each[0][1] += math.ceil(size[0] / 3)
        each[0][0] += math.ceil(size[1] / 4)
    # Center of each black square to locate white holes indicating location
    if ret:
        ul = ((corners[0][0] + corners[1][0] + corners[5][0] + corners[6][0]) / 4).astype(int)
        ur = ((corners[3][0] + corners[4][0] + corners[8][0] + corners[9][0]) / 4).astype(int)
        ll = ((corners[-5][0] + corners[-4][0] + corners[-9][0] + corners[-10][0]) / 4).astype(int)
        lr = ((corners[-1][0] + corners[-2][0] + corners[-6][0] + corners[-7][0]) / 4).astype(int)
        # NOTICE: The indicated angle is NOT the actual angle by the viewer, but a 180 degree rotated one due to Opencv coding format
        # Adding the following line change it to the real angle， but result in the rotation of coordinates given by program

        # (ul, ur, ll, lr) = (lr, ll, ur, ul)
        thresh = cv.threshold(gray, 127, 255, cv.THRESH_BINARY)[1]
        if thresh[ur[0], ur[1]] > 0 and thresh[ll[0], ll[1]] == 0:
            direction = -90
        elif thresh[lr[0], lr[1]] > 0 and thresh[ul[0], ul[1]] == 0:
            direction = 180
        elif thresh[ll[0], ll[1]] > 0 and thresh[ur[0], ur[1]] == 0:
            direction = 90
    # print('direction',str(direction))
    return direction
```

- 函数用途：确定棋盘格方位
- 利用findchessboardcorners函数返回的coner数组，取几个可能有白色圆圈的各自，然后判断像素是否为0，来确定棋盘格的方向。



## obthomography

```python
def obthomography(dst, criteria, size=800, ratio=0.04):
    # Obtain homography of the picture centred at the centre of chessboard
    h, w = dst.shape[:2]
    gray = cv.cvtColor(dst, cv.COLOR_BGR2GRAY)
    '''image = dst
    size = image.shape
    gray1 = cv.cvtColor(
        image[math.ceil(size[0] / 3):math.ceil(2 * size[0] / 3), math.ceil(size[1] / 4):math.ceil(3 * size[1] / 4)],
        cv.COLOR_BGR2GRAY)'''
    # Find the chess board corners
    ret, corners = cv.findChessboardCorners(gray, (5, 5), None)
    '''for each in corners:
        if each is not None:
            each[0][1] += math.ceil(w / 3)
            each[0][0] += math.ceil(h / 4)'''
    # corners = cv.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)
    # uncomment this line to perform subpixel detection of corner, significantly slow the speed
    # prepare corresponding points for homography
    objp2 = np.zeros((5 * 5, 2), np.float32)
    cap = max(h, w)
    k = np.mgrid[-2:3:1, -2:3:1].T.reshape(-1, 2)
    objp2[:, :2] = (k * ratio + 0.5) * cap
    pts1 = np.float32([corners[0][0], corners[4][0], corners[-1][0]])

    # rectify picture to proper orientation that make the bolts face downward
    vec = corners[4][0] - corners[0][0]
    tan = vec[1] / vec[0]
    # !! only basic cases considered !!
    if tan <= 1 and tan >= -1:
        if vec[0] >= 0:
            pts2 = np.float32([objp2[0], objp2[4], objp2[-1]])
        else:
            pts2 = np.float32([objp2[-1], objp2[-5], objp2[0]])
    else:
        if vec[1] >= 0:
            pts2 = np.float32([objp2[4], objp2[-1], objp2[-5]])
        else:
            pts2 = np.float32([objp2[-5], objp2[0], objp2[4]])

    # obtain and perform transformation
    M = cv.getAffineTransform(pts1, pts2)
    # H = cv.findHomography(corners, objp2)
    dst = cv.warpAffine(dst, M, (cap, cap))
    dst = cv.resize(dst, (size, size))
    return dst
```

- 函数用途：消除透视

- 用到getAffineTransform:  pts1? pts2? 

- ```python
  k = np.mgrid[-2:3:1, -2:3:1].T.reshape(-1, 2)
      objp2[:, :2] = (k * ratio + 0.5) * cap
  ```

- 仿射变换，又称仿射映射，是指在几何中，一个向量空间进行一次线性变换并接上一个平移，变换为另一个向量空间。仿射变换需要一个M矩阵,但是由于仿射变换比较复杂，一般直接找很难找到这个矩阵，opencv提供了根据变换前后三个点的对应关系来自动求解M的函数，这个函数就是：

  M=cv2.GetAffineTransform(src, dst)
  src：原始图像中的三个点的坐标
  dst：变换后的这三个点对应的坐标
  M：根据三个对应点求出的仿射变换矩阵
  然后再使用函数cv2.warpAffine()利用得到的M对原始图像进行变换即可



## 总结(processingimage)

- 首先用watchdog选取文件
- 用opencv找棋盘格角点
- 用opencv相机矫正
- 用DNN进行边缘识别
- 用base_grid2计算主柱中心坐标
- 寻找optimal的结果
- 消除透视

## OpenCV DNN 模块

DNN即Deep Neural Networks，也就是深层神经网络，是目前深度学习概念中最基本的一种技术框架。
 相对于传统的人工神经网络（包括多层神经网络），对DNN的关键不同点的一种解释是：**其在做有监督学习前要先做非监督学习，然后将非监督学习学到的权值当作有监督学习的初值进行训练。**

几个关键步骤如下：
 （1）载入Caffe模型

```c
Ptr<dnn::Importer> importer;
importer = dnn::createCaffeImporter(modelTxt, modelBin);   
```

（2）创建神经网络并初始化

```c
dnn::Net net;
importer->populateNet(net);
importer.release();
```

（3）读取输入图像并转化为GoogleNet可识别的blob格式

```c
Mat img = imread(imageFile);
resize(img, img, Size(224, 224));
dnn::Blob inputBlob = dnn::Blob(img); 
```

（4）将图像数据输入网络

```c
net.setBlob(".data", inputBlob);
```

（5）计算输出

```c
net.forward();
```

（6）取出prob层的输出，确定最终的分类

```c
dnn::Blob prob = net.getBlob("prob");
int classId;
double classProb;
getMaxClass(prob, &classId, &classProb);
```
